@article{Messina2007,
abstract = {The Department of Homeland Security is sponsoring development of standards for urban search and rescue (USAR) robots. This program is being coordinated by the National Institute of Standards and Technology and will result in consensus standards developed through ASTM International. Robot deployment categories and performance requirements have been identified by emergency responders, These requirements are being translated into tests and metrics with which to measure the performance of robots. Several test methods have been entered into the standards process. Three major exercises have been held at US&R training facilities, in which responders work side-by-side with robot manufacturers to experiment with robot deployments in relevant scenarios and to refine and expand performance requirements. To date, over forty robots, including ground, aerial, and aquatic, have been involved. Supporting projects are developing an ontology of robot capabilities and situational constraints. In general, these efforts will enable responders to enhance their effectiveness while reducing risk to personnel during disasters through use of robotic assets. {\textcopyright} 2007 IEEE.},
author = {Messina, Elena R. and Jacoff, Adam S.},
doi = {10.1109/THS.2007.370015},
file = {:C\:/Users/s.bazargan.TOSANTECHNO/Desktop/Measuring the Performance of Urban Search and Rescue Robots.pdf:pdf},
isbn = {1424410533},
journal = {2007 IEEE Conference on Technologies for Homeland Security: Enhancing Critical Infrastructure Dependability},
mendeley-groups = {Throwable Rescue Robot},
pages = {28--33},
title = {{Measuring the performance of urban search and rescue robots}},
year = {2007}
}

@inproceedings{Yao2022,
  abstract = {Mobile robots and many edge AI devices have a need to trade off computational power against power consumption, battery size, and time between charges. Consequently, it is common for such devices to have significantly less computational power than the powerful GPU-based systems typically used to train and evaluate deep neural networks. Object detection is a key aspect of visual perception for robots and edge devices but popular object detection architectures that run fastest on GPU based systems or that are designed to maximize mAP with large input image sizes may not scale well to edge devices. In this work we evaluate the latency and mAP of several model architectures from the YOLO and SSD families on a range of devices representative of robot and edge device capabilities. We also evaluate the effect of runtime framework and show that some unexpected large differences can be found. Based on our evaluations we propose new variations of the YOLO-LITE architecture which we show can provide increased mAP at reduced latency.},
  author = {Yao, Zheng Bai and Douglas, Will and O'Keeffe, Simon and Villing, Rudi},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  doi = {10.1007/978-3-030-98682-7_19},
  isbn = {9783030986810},
  issn = {16113349},
  pages = {226--237},
  publisher = {Springer Science and Business Media Deutschland GmbH},
  title = {{Faster YOLO-LITE: Faster Object Detection on Robot and Edge Devices}},
  volume = {13132 LNAI},
  year = {2022}
}

@misc{Mathew2014,
  author = {Mathew, Thomas J and Knox, Greig and Fong, W K and Booysen, Tracy and Marais, Stephen},
  title = {{The Design of a Rugged, Low-Cost, Man-Packable Urban Search and Rescue Robotic System}},
  howpublished = {\url{https://www.researchgate.net/profile/Tracy-Booysen/publication/270507252_The_Design_of_a_Rugged_Low-Cost_Man-Packable_Urban_Search_and_Rescue_Robotic_System/links/54abe8940cf25c4c472fb97b/The-Design-of-a-Rugged-Low-Cost-Man-Packable-Urban-Search-and-Rescu}},
  journal = {Proceedings of the 2014 PRASA, RobMech and AfLaT International Joint Symposium},
  pages = {6},
  year = {2014},
  note = {Available online}
}

@inproceedings{Karimi2017,
abstract = {We present our recent work on the electrical and hardware design of the multi-robot mobile platform WeeMiK. The goal of this project was to develop a low-cost and robust but extensible platform for research and educational purpose especially in swarm robotics. WeeMiK structure enables large-scale innovative, new curriculum, multi-agent research and mobile robot outreach to artificial intelligent students. We introduce WeeMiK platform, which offers a balance between capabilities, accessibility, cost and an open-design with open source programing SDK. All of electrical structure include sensors, motor drive, wireless communication system and device communication manager (DCM), are designed based on a 8-Bit AVR micro-controller that runs under Real-Time Operating System (freeRTOS) with tasks scheduling. With a range of different sensors like inertia navigation system (INS), IR ring for both transceiver data besides proximity, wireless communication and omnidirectional locomotion system, not only WeeMiK can interact with environment in multiple ways, but it also able to communicate with the other WeeMiKs and or PC, therefore it can be used in various swarm robotic scenarios. We demonstrate the usability of our concept by quantifying the obstacle avoidance task and also briefly describe the software design based on Arduino and freeRTOS framework for educational usage.},
annote = {ترجمه شد.},
author = {Karimi, Mojtaba and Ahmadi, Alireza and Kavandi, Parinaz and Ghidary, Saeed Shiry},
booktitle = {4th RSI International Conference on Robotics and Mechatronics, ICRoM 2016},
doi = {10.1109/ICRoM.2016.7886789},
file = {:C\:/Users/s.bazargan.TOSANTECHNO/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Karimi et al. - 2017 - WeeMiK A low-cost omnidirectional swarm platform for outreach, research and education.pdf:pdf},
isbn = {9781509032228},
keywords = {Device Communication Manager,Multi-robot Platform,Opendesign Structure,Swarm Robotics},
mendeley-groups = {Embedded systems and PCBs,Robotic Papers},
month = {mar},
pages = {26--31},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{WeeMiK: A low-cost omnidirectional swarm platform for outreach, research and education}},
year = {2017}
}

@misc{ReconRobotics_ThrowbotXT,
  author = {{Recon Robotics}},
  title = {{Recon Robotics - Throwbot XT with Audio}},
  howpublished = {\url{http://www.reconrobotics.com/products/Throwbot XT audio.cfm}},
  note = {[Online]},
}

@misc{ReconRobotics_ScoutXL,
  author = {{Recon Robotics}},
  title = {{Recon Scout XL Specification Sheet}},
  howpublished = {\url{http://www.recon-scout.com/pdfs/ReconRobotics ReconScout}},
  note = {[Online]}
}

@misc{iRobot_FirstLook,
  author = {{iRobot Corporation}},
  title = {{iRobot FirstLook Specifications}},
  year = {2012},
  howpublished = {Tech. Rep., [Online]},
  url = {http://www.irobot.com/us/robots/defense/firstlook/∼/media/Files/Robots/Defense/FirstLook/iRobot-110-FirstLook-Specs.ashx}
}

@techreport{CarmineNoviello2022,
author = {{Carmine Noviello}},
file = {:C\:/Users/s.bazargan.TOSANTECHNO/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carmine Noviello - 2022 - Mastering STM32-Second Edition.pdf:pdf},
mendeley-groups = {Embedded systems and PCBs},
title = {{Mastering STM32-Second Edition}},
url = {http://leanpub.com/mastering-stm32-2nd},
year = {2022}
}

@article{GUAN201619,
title = {Open source FreeRTOS as a case study in real-time operating system evolution},
journal = {Journal of Systems and Software},
volume = {118},
pages = {19-35},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.04.063},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300383},
author = {Fei Guan and Long Peng and Luc Perneel and Martin Timmerman},
keywords = {Embedded system, FreeRTOS, Real-time OS, Software evolution},
abstract = {This paper studies the evolution of a real-time operating system, the open source FreeRTOS. We focus on the changes in real-time performance and behaviour over the last ten years. Six major release versions are benchmarked, presenting quantitative and qualitative development trends. We also use the available source code to discover the reasons for the changes. By analysing the results, we draw some conclusions related to this RTOS’s evolution which can be useful for the FreeRTOS group, other RTOS developments, and also RTOS users.}
}

@article{teimouri2018mrl,
  title={MRL Team Description Paper for Humanoid KidSize League of RoboCup 2018},
  author={Teimouri, Meisam and Salimi, Amir and Farhadi, Ashkan and Fatehi, Alireza and Mahmoudi, Hamed and Sharifi, Hamed and Sefat, Mohammad Hosseini},
  journal={Mechatronics Research Lab, Department of Computer and Electrical Engineering, Qazvin Islamic Azad University, Qazvin, Iran},
  year={2018}
}

@inproceedings{Han2021,
abstract = {In Automatic Driving System (ADS) and Driver Assistance System (DAS), object detection plays a vital part. Nevertheless, existing real-time detection models for tiny vehicle objects have the problems of low precision and poor performance. To solve these issues, we propose a novel real-time object detection model based on You Only Look Once Version 2 (YOLO-v2) deep learning framework for tiny vehicle objects, called Optimized You Only Look Once Version 2 (O-YOLO-v2). In the proposed model, a new structure is introduced to strengthen the feature extraction ability of the network by adding convolution layers at different locations. Meanwhile, the problem of gradient disappearance or dispersion caused by increasing network depth is solved by adding residual modules. Furthermore, in order to promote the detection accuracy of tiny vehicle objects, we combine the low-level features and high-level features of the network. The experimental findings and analysis on a KITTI dataset show that the model not only promotes the accuracy of tiny vehicle object detection but also improves the accuracy of vehicle detection (the accuracy reaches 94%) without decreasing the detection speed.},
annote = {ترجمه شد.},
author = {Han, Xiaohong and Chang, Jun and Wang, Kaiyuan},
booktitle = {Procedia Computer Science},
doi = {10.1016/j.procs.2021.02.031},
file = {:C\:/Users/s.bazargan.TOSANTECHNO/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Chang, Wang - 2021 - Real-time object detection based on YOLO-v2 for tiny vehicle object.pdf:pdf},
issn = {18770509},
keywords = {Deep learning,Feature fusion,Residual module,Tiny vehicle detection,YOLO-v2},
mendeley-groups = {Throwable Rescue Robot},
pages = {61--72},
publisher = {Elsevier B.V.},
title = {{Real-time object detection based on YOLO-v2 for tiny vehicle object}},
volume = {183},
year = {2021}
}

@incollection{braunl2006embedded,
  title={Embedded Robotics: Mobile Robot Design and Application with Embedded Systems},
  author={Braunl, Thomas},
  booktitle={Not available},
  pages={458},
  year={2006},
  publisher={Springer}
}

@manual{STM32_ReferenceManual,
  author = {{STMicroelectronics}},
  title = {{RM0008 Reference Manual: STM32F101xx, STM32F102xx, STM32F103xx, STM32F105xx, and STM32F107xx Advanced ARM-based Microcontrollers}},
  note = {[Online]},
  url = {https://www.st.com/resource/en/reference_manual/rm0008-stm32f101xx-stm32f102xx-stm32f103xx-stm32f105xx-and-stm32f107xx-advanced-arm-based-32-bit-mcus-stmicroelectronics.pdf}
}

